{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a52bdb8",
   "metadata": {},
   "source": [
    "**Part 1: Model based on spotify features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990edf68",
   "metadata": {},
   "source": [
    "**Step 1: Get data from all albums into one dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "f6e09dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/1989 (Taylor_s Version) [Deluxe]_with_avg.csv\"\n",
    "albums = []\n",
    "albums_no_red = []\n",
    "\n",
    "tv_1989 = pd.read_csv(directory, index_col=2)\n",
    "\n",
    "tv_1989.drop('Unnamed: 0.1', inplace=True, axis=1) \n",
    "tv_1989.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "tv_1989 = tv_1989.drop(tv_1989.index[22])\n",
    "\n",
    "for x in range(len(tv_1989)):\n",
    "    albums.append(tv_1989['Album (if applicable)'][1])\n",
    "    albums_no_red.append(tv_1989['Album (if applicable)'][1])\n",
    "\n",
    "tv_1989.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "tv_1989.drop('Release Date', inplace=True, axis=1) \n",
    "tv_1989.drop('URI', inplace=True, axis=1) \n",
    "tv_1989.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "15b97b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/evermore (deluxe version)_with_avg.csv\"\n",
    "\n",
    "tv_evermore = pd.read_csv(directory, index_col=2)\n",
    "\n",
    "tv_evermore.drop('Unnamed: 0.1', inplace=True, axis=1) \n",
    "tv_evermore.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "tv_evermore = tv_evermore.drop(tv_evermore.index[17])\n",
    "\n",
    "for x in range(len(tv_evermore)):\n",
    "    albums.append(tv_evermore['Album (if applicable)'][1])\n",
    "    albums_no_red.append(tv_evermore['Album (if applicable)'][1])\n",
    "\n",
    "tv_evermore.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "tv_evermore.drop('Release Date', inplace=True, axis=1) \n",
    "tv_evermore.drop('URI', inplace=True, axis=1) \n",
    "tv_evermore.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "d8f5c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pd.concat([tv_1989, tv_evermore])\n",
    "all_songs_no_red = pd.concat([tv_1989, tv_evermore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "8b433aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/Fearless (Taylor_s Version)_with_avg.csv\"\n",
    "\n",
    "tv_fearless = pd.read_csv(directory, index_col=2)\n",
    "\n",
    "tv_fearless.drop('Unnamed: 0.1', inplace=True, axis=1) \n",
    "tv_fearless.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "tv_fearless = tv_fearless.drop(tv_fearless.index[26])\n",
    "\n",
    "for x in range(len(tv_fearless)):\n",
    "    albums.append(tv_fearless['Album (if applicable)'][1])\n",
    "    albums_no_red.append(tv_fearless['Album (if applicable)'][1])\n",
    "\n",
    "tv_fearless.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "tv_fearless.drop('Release Date', inplace=True, axis=1) \n",
    "tv_fearless.drop('URI', inplace=True, axis=1) \n",
    "tv_fearless.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "74195b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pd.concat([all_songs, tv_fearless])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, tv_fearless])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "6119189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/Red (Taylor_s Version)_with_avg.csv\"\n",
    "\n",
    "tv_red = pd.read_csv(directory, index_col=2)\n",
    "\n",
    "tv_red.drop('Unnamed: 0.1', inplace=True, axis=1) \n",
    "tv_red.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "tv_red = tv_red.drop(tv_red.index[30])\n",
    "\n",
    "for x in range(len(tv_red)):\n",
    "    albums.append(tv_red['Album (if applicable)'][1])\n",
    "\n",
    "tv_red.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "tv_red.drop('Release Date', inplace=True, axis=1) \n",
    "tv_red.drop('URI', inplace=True, axis=1) \n",
    "tv_red.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "5f1904b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pd.concat([all_songs, tv_red])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "a348ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/Speak Now (Taylor_s Version)_with_avg.csv\"\n",
    "\n",
    "tv_speaknow = pd.read_csv(directory, index_col=2)\n",
    "\n",
    "tv_speaknow.drop('Unnamed: 0.1', inplace=True, axis=1) \n",
    "tv_speaknow.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "tv_speaknow = tv_speaknow.drop(tv_speaknow.index[22])\n",
    "\n",
    "for x in range(len(tv_speaknow)):\n",
    "    albums.append(tv_speaknow['Album (if applicable)'][1])\n",
    "    albums_no_red.append(tv_speaknow['Album (if applicable)'][1])\n",
    "\n",
    "tv_speaknow.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "tv_speaknow.drop('Release Date', inplace=True, axis=1) \n",
    "tv_speaknow.drop('URI', inplace=True, axis=1) \n",
    "tv_speaknow.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "fac1e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pd.concat([all_songs, tv_speaknow])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, tv_speaknow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "de49b809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/folklore (deluxe version).csv\"\n",
    "\n",
    "folklore = pd.read_csv(directory, index_col=1)\n",
    "\n",
    "folklore.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "folklore = folklore.drop(folklore.index[16])\n",
    "\n",
    "for x in range(len(folklore)):\n",
    "    albums.append(folklore['Album (if applicable)'][1])\n",
    "    albums_no_red.append(folklore['Album (if applicable)'][1])\n",
    "\n",
    "folklore.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "folklore.drop('Release Date', inplace=True, axis=1) \n",
    "folklore.drop('URI', inplace=True, axis=1) \n",
    "folklore.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "8a860e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/4229715448.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs = pd.concat([all_songs, folklore])\n",
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/4229715448.py:2: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs_no_red = pd.concat([all_songs_no_red, folklore])\n"
     ]
    }
   ],
   "source": [
    "all_songs = pd.concat([all_songs, folklore])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, folklore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "d35e4082",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/Lover.csv\"\n",
    "\n",
    "lover = pd.read_csv(directory, index_col=1)\n",
    "\n",
    "lover.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "lover = lover.drop(lover.index[len(lover) - 1])\n",
    "\n",
    "for x in range(len(lover)):\n",
    "    albums.append(lover['Album (if applicable)'][1])\n",
    "    albums_no_red.append(lover['Album (if applicable)'][1])\n",
    "\n",
    "lover.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "lover.drop('Release Date', inplace=True, axis=1) \n",
    "lover.drop('URI', inplace=True, axis=1) \n",
    "lover.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "e154687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/2026415425.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs = pd.concat([all_songs, lover])\n",
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/2026415425.py:2: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs_no_red = pd.concat([all_songs_no_red, lover])\n"
     ]
    }
   ],
   "source": [
    "all_songs = pd.concat([all_songs, lover])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, lover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "eb3e9f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/Midnights (The Til Dawn Edition).csv\"\n",
    "\n",
    "midnights = pd.read_csv(directory, index_col=1)\n",
    "\n",
    "midnights.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "midnights = midnights.drop(midnights.index[len(midnights) - 1])\n",
    "\n",
    "for x in range(len(midnights)):\n",
    "    albums.append(midnights['Album (if applicable)'][1])\n",
    "    albums_no_red.append(midnights['Album (if applicable)'][1])\n",
    "\n",
    "midnights.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "midnights.drop('Release Date', inplace=True, axis=1) \n",
    "midnights.drop('URI', inplace=True, axis=1) \n",
    "midnights.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "7b91ff94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/3802949316.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs = pd.concat([all_songs, midnights])\n",
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/3802949316.py:2: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs_no_red = pd.concat([all_songs_no_red, midnights])\n"
     ]
    }
   ],
   "source": [
    "all_songs = pd.concat([all_songs, midnights])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, midnights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "db1a7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/reputation.csv\"\n",
    "\n",
    "reputation = pd.read_csv(directory, index_col=1)\n",
    "\n",
    "reputation.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "reputation = reputation.drop(reputation.index[len(reputation) - 1])\n",
    "\n",
    "for x in range(len(reputation)):\n",
    "    albums.append(reputation['Album (if applicable)'][1])\n",
    "    albums_no_red.append(reputation['Album (if applicable)'][1])\n",
    "\n",
    "reputation.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "reputation.drop('Release Date', inplace=True, axis=1) \n",
    "reputation.drop('URI', inplace=True, axis=1) \n",
    "reputation.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "558641a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/644132513.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs = pd.concat([all_songs, reputation])\n",
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/644132513.py:2: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs_no_red = pd.concat([all_songs_no_red, reputation])\n"
     ]
    }
   ],
   "source": [
    "all_songs = pd.concat([all_songs, reputation])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, reputation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "826f1fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/lucykopin/Documents/DIS/Data Analysis/TS Data/Taylor Swift.csv\"\n",
    "\n",
    "taylorswift = pd.read_csv(directory, index_col=1)\n",
    "\n",
    "taylorswift.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "taylorswift = taylorswift.drop(taylorswift.index[len(taylorswift) - 1])\n",
    "\n",
    "for x in range(len(taylorswift)):\n",
    "    albums.append(taylorswift['Album (if applicable)'][1])\n",
    "    albums_no_red.append(taylorswift['Album (if applicable)'][1])\n",
    "\n",
    "taylorswift.drop('Album (if applicable)', inplace=True, axis=1) \n",
    "taylorswift.drop('Release Date', inplace=True, axis=1) \n",
    "taylorswift.drop('URI', inplace=True, axis=1) \n",
    "taylorswift.drop('Time Signature', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "b5a4eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/2958539820.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs = pd.concat([all_songs, taylorswift])\n",
      "/var/folders/my/_dbqkgsj67ndzlb44t3s30lh0000gn/T/ipykernel_32392/2958539820.py:2: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  all_songs_no_red = pd.concat([all_songs_no_red, taylorswift])\n"
     ]
    }
   ],
   "source": [
    "all_songs = pd.concat([all_songs, taylorswift])\n",
    "all_songs_no_red = pd.concat([all_songs_no_red, taylorswift])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96706672",
   "metadata": {},
   "source": [
    "**Step 2: Train and test models on all songs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "aa919ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-62 {color: black;}#sk-container-id-62 pre{padding: 0;}#sk-container-id-62 div.sk-toggleable {background-color: white;}#sk-container-id-62 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-62 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-62 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-62 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-62 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-62 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-62 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-62 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-62 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-62 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-62 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-62 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-62 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-62 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-62 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-62 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-62 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-62 div.sk-item {position: relative;z-index: 1;}#sk-container-id-62 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-62 div.sk-item::before, #sk-container-id-62 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-62 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-62 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-62 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-62 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-62 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-62 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-62 div.sk-label-container {text-align: center;}#sk-container-id-62 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-62 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-62\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" checked><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model.fit(all_songs, albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "c1746243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.255\n",
      "\n",
      "Baseline Accuracies:\n",
      "1989: 0.11\n",
      "Evermore: 0.085\n",
      "Fearless: 0.13\n",
      "Red: 0.15\n",
      "Speak Now: 0.11\n",
      "Folklore: 0.08\n",
      "Lover: 0.085\n",
      "Midnights: 0.11\n",
      "Reputation: 0.07\n",
      "Taylor Swift: 0.07\n",
      "\n",
      "Training Accuracy Top 3: 0.62\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(all_songs)\n",
    "\n",
    "for i in range(len(albums)):\n",
    "    if albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(albums)\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "print()\n",
    "\n",
    "print(\"Baseline Accuracies:\")\n",
    "print(\"1989:\", albums.count(\"1989 (Taylor's Version) [Deluxe]\") / len(albums))\n",
    "print(\"Evermore:\", albums.count(\"evermore (deluxe version)\") / len(albums))\n",
    "print(\"Fearless:\", albums.count(\"Fearless (Taylor's Version)\") / len(albums))\n",
    "print(\"Red:\", albums.count(\"Red (Taylor's Version)\") / len(albums))\n",
    "print(\"Speak Now:\", albums.count(\"Speak Now (Taylor's Version)\") / len(albums))\n",
    "print(\"Folklore:\", albums.count(\"folklore (deluxe version)\") / len(albums))\n",
    "print(\"Lover:\", albums.count(\"Lover\") / len(albums))\n",
    "print(\"Midnights:\", albums.count(\"Midnights (The Til Dawn Edition)\") / len(albums))\n",
    "print(\"Reputation:\", albums.count(\"reputation\") / len(albums))\n",
    "print(\"Taylor Swift:\", albums.count(\"Taylor Swift\") / len(albums))\n",
    "print()\n",
    "\n",
    "probabilities = model.predict_proba(all_songs)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "\n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(albums)):\n",
    "    if albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(albums)\n",
    "print(\"Training Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec84ca",
   "metadata": {},
   "source": [
    "**Step 2a: Red has the most songs by almost double of most of her other albums. What if we try the model without red?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "b93e4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3235294117647059\n",
      "\n",
      "Baseline Accuracies:\n",
      "1989: 0.12941176470588237\n",
      "Evermore: 0.1\n",
      "Fearless: 0.15294117647058825\n",
      "Speak Now: 0.12941176470588237\n",
      "Folklore: 0.09411764705882353\n",
      "Lover: 0.1\n",
      "Midnights: 0.12941176470588237\n",
      "Reputation: 0.08235294117647059\n",
      "Taylor Swift: 0.08235294117647059\n",
      "\n",
      "Training Accuracy Top 3: 0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "model.fit(all_songs_no_red, albums_no_red)\n",
    "\n",
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(all_songs_no_red)\n",
    "\n",
    "for i in range(len(albums_no_red)):\n",
    "    if albums_no_red[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(albums_no_red)\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "print()\n",
    "\n",
    "print(\"Baseline Accuracies:\")\n",
    "print(\"1989:\", albums.count(\"1989 (Taylor's Version) [Deluxe]\") / len(albums_no_red))\n",
    "print(\"Evermore:\", albums.count(\"evermore (deluxe version)\") / len(albums_no_red))\n",
    "print(\"Fearless:\", albums.count(\"Fearless (Taylor's Version)\") / len(albums_no_red))\n",
    "print(\"Speak Now:\", albums.count(\"Speak Now (Taylor's Version)\") / len(albums_no_red))\n",
    "print(\"Folklore:\", albums.count(\"folklore (deluxe version)\") / len(albums_no_red))\n",
    "print(\"Lover:\", albums.count(\"Lover\") / len(albums_no_red))\n",
    "print(\"Midnights:\", albums.count(\"Midnights (The Til Dawn Edition)\") / len(albums_no_red))\n",
    "print(\"Reputation:\", albums.count(\"reputation\") / len(albums_no_red))\n",
    "print(\"Taylor Swift:\", albums.count(\"Taylor Swift\") / len(albums_no_red))\n",
    "print()\n",
    "\n",
    "probabilities = model.predict_proba(all_songs_no_red)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "\n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(albums_no_red)):\n",
    "    if albums_no_red[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(albums_no_red)\n",
    "print(\"Training Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d8d6d",
   "metadata": {},
   "source": [
    "**Step 2b: Split all songs into 2 training and test data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "3dd55cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame(all_songs.iloc[0]).T\n",
    "training_albums = []\n",
    "training_albums.append(albums[0])\n",
    "\n",
    "\n",
    "test = pd.DataFrame(all_songs.iloc[1]).T\n",
    "test_albums = []\n",
    "test_albums.append(albums[1])\n",
    "\n",
    "for x in range(2, len(all_songs)):\n",
    "    if x % 2 == 0:\n",
    "        training = pd.concat([training, pd.DataFrame(all_songs.iloc[x]).T])\n",
    "        training_albums.append(albums[x])\n",
    "    else:\n",
    "        test = pd.concat([test, pd.DataFrame(all_songs.iloc[x]).T])\n",
    "        test_albums.append(albums[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "fb5bfa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-63 {color: black;}#sk-container-id-63 pre{padding: 0;}#sk-container-id-63 div.sk-toggleable {background-color: white;}#sk-container-id-63 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-63 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-63 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-63 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-63 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-63 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-63 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-63 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-63 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-63 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-63 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-63 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-63 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-63 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-63 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-63 div.sk-item {position: relative;z-index: 1;}#sk-container-id-63 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-63 div.sk-item::before, #sk-container-id-63 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-63 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-63 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-63 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-63 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-63 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-63 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-63 div.sk-label-container {text-align: center;}#sk-container-id-63 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-63 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-63\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" checked><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training, training_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "988af496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.18\n",
      "Test Accuracy Top 3: 0.51\n",
      "\n",
      "Training Accuracy: 0.29\n",
      "Training Accuracy Top 3: 0.66\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(test)\n",
    "\n",
    "for i in range(len(test_albums)):\n",
    "    if test_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "test_accuracy = correct / len(test_albums)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(test)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(test_albums)):\n",
    "    if test_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "test_accuracy = correct / len(test_albums)\n",
    "print(\"Test Accuracy Top 3:\", test_accuracy)\n",
    "print()\n",
    "\n",
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(training)\n",
    "\n",
    "for i in range(len(training_albums)):\n",
    "    if training_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(training_albums)\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(training)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(training_albums)):\n",
    "    if training_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(training_albums)\n",
    "print(\"Training Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c5ca7",
   "metadata": {},
   "source": [
    "**Model 1 With all Songs Tested On Vault Tracks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "4faa6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vault_albums = []\n",
    "\n",
    "vault_songs = pd.DataFrame(tv_1989.iloc[20]).T\n",
    "vault_albums.append(albums[20])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(tv_1989.iloc[19]).T])\n",
    "vault_albums.append(albums[19])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(tv_1989.iloc[18]).T])\n",
    "vault_albums.append(albums[18])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(tv_1989.iloc[17]).T])\n",
    "vault_albums.append(albums[17])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(tv_1989.iloc[16]).T])\n",
    "vault_albums.append(albums[16])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[59]).T])\n",
    "vault_albums.append(albums[59])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[60]).T])\n",
    "vault_albums.append(albums[60])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[61]).T])\n",
    "vault_albums.append(albums[61])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[62]).T])\n",
    "vault_albums.append(albums[62])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[63]).T])\n",
    "vault_albums.append(albums[63])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[64]).T])\n",
    "vault_albums.append(albums[64])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[86]).T])\n",
    "vault_albums.append(albums[86])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[87]).T])\n",
    "vault_albums.append(albums[87])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[88]).T])\n",
    "vault_albums.append(albums[88])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[89]).T])\n",
    "vault_albums.append(albums[89])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[90]).T])\n",
    "vault_albums.append(albums[90])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[91]).T])\n",
    "vault_albums.append(albums[91])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[92]).T])\n",
    "vault_albums.append(albums[92])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[93]).T])\n",
    "vault_albums.append(albums[93])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[94]).T])\n",
    "vault_albums.append(albums[94])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[111]).T])\n",
    "vault_albums.append(albums[111])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[112]).T])\n",
    "vault_albums.append(albums[112])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[113]).T])\n",
    "vault_albums.append(albums[113])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[114]).T])\n",
    "vault_albums.append(albums[114])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[115]).T])\n",
    "vault_albums.append(albums[115])\n",
    "\n",
    "vault_songs = pd.concat([vault_songs, pd.DataFrame(all_songs.iloc[116]).T])\n",
    "vault_albums.append(albums[116])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "38ed76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vault_albums = albums.copy()\n",
    "\n",
    "non_vault_albums.pop(19)\n",
    "\n",
    "non_vault = all_songs.drop(all_songs.index[19])\n",
    "\n",
    "non_vault_albums.pop(19)\n",
    "non_vault = non_vault.drop(non_vault.index[19])\n",
    "\n",
    "non_vault_albums.pop(18)\n",
    "non_vault = non_vault.drop(non_vault.index[18])\n",
    "\n",
    "non_vault_albums.pop(17)\n",
    "non_vault = non_vault.drop(non_vault.index[17])\n",
    "\n",
    "non_vault_albums.pop(16)\n",
    "non_vault = non_vault.drop(non_vault.index[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "f8446845",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vault_albums.pop(54)\n",
    "non_vault = non_vault.drop(non_vault.index[54]) \n",
    "\n",
    "non_vault_albums.pop(54)\n",
    "non_vault = non_vault.drop(non_vault.index[54]) \n",
    "\n",
    "non_vault_albums.pop(54)\n",
    "non_vault = non_vault.drop(non_vault.index[54])\n",
    "\n",
    "non_vault_albums.pop(54)\n",
    "non_vault = non_vault.drop(non_vault.index[54])\n",
    "\n",
    "non_vault_albums.pop(54)\n",
    "non_vault = non_vault.drop(non_vault.index[54]) \n",
    "\n",
    "non_vault_albums.pop(54)\n",
    "non_vault = non_vault.drop(non_vault.index[54])\n",
    "\n",
    "for x in range(0,9):\n",
    "    non_vault_albums.pop(75)\n",
    "    non_vault = non_vault.drop(non_vault.index[75])\n",
    "    \n",
    "for x in range(0,6):\n",
    "    non_vault_albums.pop(91)\n",
    "    non_vault = non_vault.drop(non_vault.index[91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "460fab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-64 {color: black;}#sk-container-id-64 pre{padding: 0;}#sk-container-id-64 div.sk-toggleable {background-color: white;}#sk-container-id-64 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-64 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-64 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-64 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-64 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-64 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-64 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-64 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-64 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-64 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-64 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-64 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-64 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-64 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-64 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-64 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-64 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-64 div.sk-item {position: relative;z-index: 1;}#sk-container-id-64 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-64 div.sk-item::before, #sk-container-id-64 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-64 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-64 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-64 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-64 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-64 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-64 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-64 div.sk-label-container {text-align: center;}#sk-container-id-64 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-64 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-64\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" checked><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(non_vault, non_vault_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "190e3992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vault Songs Accuracy: 0.23076923076923078\n",
      "Vault Songs Accuracy Top 3: 0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(vault_songs)\n",
    "\n",
    "for i in range(len(vault_albums)):\n",
    "    if vault_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(vault_albums)\n",
    "print(\"Vault Songs Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(vault_songs)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(vault_albums)):\n",
    "    if vault_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(vault_albums)\n",
    "print(\"Vault Songs Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "0a9e5cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-vault Accuracy: 0.26436781609195403\n",
      "\n",
      "Non-vault Accuracy Top 3: 0.603448275862069\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(non_vault)\n",
    "\n",
    "for i in range(len(non_vault_albums)):\n",
    "    if non_vault_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(non_vault_albums)\n",
    "print(\"Non-vault Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(non_vault)\n",
    "\n",
    "classes = model.classes_\n",
    "print()\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(non_vault_albums)):\n",
    "    if non_vault_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(non_vault_albums)\n",
    "print(\"Non-vault Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3fab3",
   "metadata": {},
   "source": [
    "**Part 2: Model based on bag of words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "25bedd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Get list of stopwords and add a few\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_clean_words(text, exclude_words=[]):\n",
    "    \"\"\"Given some text, return a list of clean words.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "        text : str\n",
    "        exclude_words : list\n",
    "            Words to exclude (e.g. characters own name)\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "        words : list\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "        >>> my_text = get_clean_text('Iron Man', 'heroes')\n",
    "        >>> my_words = get_clean_words(my_text, exclude_words=['Iron', 'Man'])\n",
    "    \"\"\"\n",
    "\n",
    "    # Extarct words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Add exclude words to words to give it same treatment\n",
    "    words += exclude_words\n",
    "    \n",
    "    # Convert to lower case\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    # Clear punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [w.translate(table) for w in words]\n",
    "    \n",
    "    # Seperate words and exclude words\n",
    "    if len(exclude_words) > 0:\n",
    "        exclude_words = words[-len(exclude_words):]\n",
    "        words = words[:-len(exclude_words)]\n",
    "    \n",
    "    # Remove non-alphabetic words\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [w for w in words if not w in stop_words | set(exclude_words)]\n",
    "    \n",
    "    # Remove single letter words \n",
    "    words = [w for w in words if len(w) > 1]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "676af41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def get_clean_text(title, folder):\n",
    "    \"\"\"Given a character name (title) and the faction it belongs to\n",
    "    return the page markup as a neatly cleaned string.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "        title : str\n",
    "        folder : str\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "        text : str\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "        >>> get_clean_text('Iron Man', 'heroes')\n",
    "    \"\"\"\n",
    "    # Load markup\n",
    "    with open(f\"./{folder}/{title}\") as fp:\n",
    "        text = fp.read()\n",
    "\n",
    "    # Remove category links\n",
    "    text = re.sub(r'\\[\\[Category.+\\]\\]', '', text)\n",
    "    \n",
    "    # Fix links (match and clear \"[[Iron Man (comic book)|\" and \"[[\", then on next line \"]]\"\n",
    "    text = re.sub(r'(\\[\\[((?!\\]\\]).)+\\|)|(\\[\\[)', '', text)\n",
    "    text = re.sub(r'\\]\\]', '', text)\n",
    "    \n",
    "    # Remove '''\n",
    "    text = re.sub(r\"'''\", '', text)\n",
    "    \n",
    "    # Remove refs\n",
    "    text = re.sub(r'<ref.+?</ref>', '', text)\n",
    "    \n",
    "    # Remove other ugly html links\n",
    "    text = re.sub(r'<.+?>', '', text)\n",
    "    \n",
    "    # Remove '=' signs in headers\n",
    "    text = re.sub(r'=+', '', text)\n",
    "    \n",
    "    # Remove table and external links\n",
    "    text = re.sub(r'\\{\\{[\\w\\W]*?\\}\\}', '', text)\n",
    "    \n",
    "    # Remove everything after \"See Also\"\n",
    "    text = re.sub(r'== ?See [aA]lso[\\w\\W]+', \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98f3ff",
   "metadata": {},
   "source": [
    "**Step 1: Make the bag of words matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "1acfeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "for folder in os.listdir(\"lyrics\"):\n",
    "    if (folder != \".DS_Store\"):\n",
    "        for file in os.listdir(f'/Users/lucykopin/Documents/DIS/Data Analysis/lyrics/{folder}'):\n",
    "            if (file != \".DS_Store\" and file != \".ipynb_checkpoints\"):\n",
    "                    text = get_clean_text(file, f\"lyrics/{folder}\")\n",
    "                    char_text = get_clean_words(text)\n",
    "                    words.update(char_text)\n",
    "\n",
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "6fd564ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_no_red = []\n",
    "bow = []\n",
    "targets = []\n",
    "targets_no_red = []\n",
    "char_counts = {}\n",
    "\n",
    "for folder in os.listdir(\"lyrics\"):\n",
    "    if (folder != \".DS_Store\"):\n",
    "        for file in os.listdir(f'/Users/lucykopin/Documents/DIS/Data Analysis/lyrics/{folder}'):\n",
    "            if (file != \".DS_Store\" and file != \".ipynb_checkpoints\"):\n",
    "                name = file.replace(\".txt\", \"\")\n",
    "                text = get_clean_text(file, f\"lyrics/{folder}\")\n",
    "                temp_words = get_clean_words(text, \"\")\n",
    "                temp = [0] * len(words)\n",
    "                char_words = set(temp_words)\n",
    "                for x in temp_words:\n",
    "                    temp[words.index(x)] += 1\n",
    "                for x in char_words:\n",
    "                    if char_counts.get(x) == None:\n",
    "                        char_counts.update({x : 1})\n",
    "                    else:\n",
    "                        char_counts.update({x : char_counts[x] + 1})\n",
    "                        \n",
    "                bow.append(temp)\n",
    "                targets.append(folder)\n",
    "                if (folder != \"red\"):\n",
    "                    bow_no_red.append(temp)\n",
    "                    targets_no_red.append(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c358795",
   "metadata": {},
   "source": [
    "**Step 2: Train a model based on the BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "a0b295e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-65 {color: black;}#sk-container-id-65 pre{padding: 0;}#sk-container-id-65 div.sk-toggleable {background-color: white;}#sk-container-id-65 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-65 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-65 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-65 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-65 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-65 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-65 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-65 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-65 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-65 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-65 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-65 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-65 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-65 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-65 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-65 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-65 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-65 div.sk-item {position: relative;z-index: 1;}#sk-container-id-65 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-65 div.sk-item::before, #sk-container-id-65 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-65 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-65 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-65 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-65 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-65 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-65 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-65 div.sk-label-container {text-align: center;}#sk-container-id-65 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-65 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-65\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" checked><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(bow, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "14ea42dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42\n",
      "\n",
      "Accuracy Top 3: 0.805\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(bow)\n",
    "\n",
    "for i in range(len(bow)):\n",
    "    if targets[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow)\n",
    "print(\"Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(bow)\n",
    "\n",
    "classes = model.classes_\n",
    "print()\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "\n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(bow)):\n",
    "    if targets[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow)\n",
    "print(\"Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7cc5c",
   "metadata": {},
   "source": [
    "**Step 2a: Train the model again with no red:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "3ae8fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5764705882352941\n",
      "\n",
      "Accuracy Top 3: 0.8470588235294118\n"
     ]
    }
   ],
   "source": [
    "model.fit(bow_no_red, targets_no_red)\n",
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(bow_no_red)\n",
    "\n",
    "for i in range(len(bow_no_red)):\n",
    "    if targets_no_red[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow_no_red)\n",
    "print(\"Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(bow_no_red)\n",
    "\n",
    "classes = model.classes_\n",
    "print()\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "\n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(bow_no_red)):\n",
    "    if targets_no_red[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow_no_red)\n",
    "print(\"Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86adb895",
   "metadata": {},
   "source": [
    "**Step 2b: Split data into test and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "f830f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [0] * 100\n",
    "training_albums = []\n",
    "\n",
    "\n",
    "test = [0] * 100\n",
    "test_albums = []\n",
    "\n",
    "count = 0;\n",
    "\n",
    "for x in range(0, len(bow)):\n",
    "    if x % 2 == 0:\n",
    "        training[count] = bow[x]\n",
    "        training_albums.append(targets[x])\n",
    "    else:\n",
    "        test[count] = bow[x]\n",
    "        test_albums.append(targets[x])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "eadf2388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-66 {color: black;}#sk-container-id-66 pre{padding: 0;}#sk-container-id-66 div.sk-toggleable {background-color: white;}#sk-container-id-66 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-66 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-66 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-66 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-66 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-66 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-66 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-66 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-66 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-66 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-66 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-66 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-66 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-66 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-66 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-66 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-66 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-66 div.sk-item {position: relative;z-index: 1;}#sk-container-id-66 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-66 div.sk-item::before, #sk-container-id-66 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-66 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-66 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-66 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-66 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-66 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-66 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-66 div.sk-label-container {text-align: center;}#sk-container-id-66 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-66 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-66\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" checked><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training, training_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "82dff27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.15\n",
      "Test Accuracy Top 3: 0.41\n",
      "\n",
      "Training Accuracy: 0.2\n",
      "Training Accuracy Top 3: 0.67\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "result = model.predict(test)\n",
    "\n",
    "for i in range(len(test_albums)):\n",
    "    if test_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "test_accuracy = correct / len(test_albums)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(test)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    if test_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "test_accuracy = correct / len(test)\n",
    "print(\"Test Accuracy Top 3:\", test_accuracy)\n",
    "print()\n",
    "\n",
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(training)\n",
    "\n",
    "for i in range(len(training_albums)):\n",
    "    if training_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(training_albums)\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(training)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(training)):\n",
    "    if training_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(training_albums)\n",
    "print(\"Training Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce142e",
   "metadata": {},
   "source": [
    "**Step 2c: Try with a smaller test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "60ba8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [0] * 180\n",
    "training_albums = []\n",
    "\n",
    "\n",
    "test = [0] * 20\n",
    "test_albums = []\n",
    "\n",
    "training_ind = 0;\n",
    "test_ind = 0\n",
    "\n",
    "for x in range(0, len(bow)):\n",
    "    if x % 10 != 0:\n",
    "        training[training_ind] = bow[x]\n",
    "        training_albums.append(targets[x])\n",
    "        training_ind += 1\n",
    "    else:\n",
    "        test[test_ind] = bow[x]\n",
    "        test_albums.append(targets[x])\n",
    "        test_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "4c763489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-67 {color: black;}#sk-container-id-67 pre{padding: 0;}#sk-container-id-67 div.sk-toggleable {background-color: white;}#sk-container-id-67 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-67 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-67 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-67 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-67 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-67 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-67 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-67 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-67 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-67 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-67 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-67 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-67 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-67 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-67 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-67 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-67 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-67 div.sk-item {position: relative;z-index: 1;}#sk-container-id-67 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-67 div.sk-item::before, #sk-container-id-67 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-67 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-67 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-67 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-67 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-67 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-67 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-67 div.sk-label-container {text-align: center;}#sk-container-id-67 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-67 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-67\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" checked><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training, training_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "d9cf0132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.15\n",
      "Accuracy Top 3: 0.4\n",
      "\n",
      "Training Accuracy: 0.39444444444444443\n",
      "Training Accuracy Top 3: 0.7888888888888889\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "result = model.predict(test)\n",
    "\n",
    "for i in range(len(test_albums)):\n",
    "    if test_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "test_accuracy = correct / len(test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(test)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    if test_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "test_accuracy = correct / len(test)\n",
    "print(\"Accuracy Top 3:\", test_accuracy)\n",
    "print()\n",
    "\n",
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(training)\n",
    "\n",
    "for i in range(len(training_albums)):\n",
    "    if training_albums[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(training_albums)\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(training)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(training)):\n",
    "    if training_albums[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(training_albums)\n",
    "print(\"Training Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b640e19",
   "metadata": {},
   "source": [
    "**Step 3: Make a separate bag of words with the vault songs and train the model on this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "2f7305db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_non_vault = []\n",
    "targets_non_vault = []\n",
    "char_counts = {}\n",
    "\n",
    "bow_vault = []\n",
    "targets_vault = []\n",
    "\n",
    "for folder in os.listdir(\"lyrics\"):\n",
    "    if (folder != \".DS_Store\"):\n",
    "        for file in os.listdir(f'/Users/lucykopin/Documents/DIS/Data Analysis/lyrics/{folder}'):\n",
    "            if (file != \".DS_Store\" and file != \".ipynb_checkpoints\" and \"from the vault\" not in file.lower()):\n",
    "                name = file.replace(\".txt\", \"\")\n",
    "                text = get_clean_text(file, f\"lyrics/{folder}\")\n",
    "                temp_words = get_clean_words(text, \"\")\n",
    "                temp = [0] * len(words)\n",
    "                char_words = set(temp_words)\n",
    "                for x in temp_words:\n",
    "                    temp[words.index(x)] += 1\n",
    "                for x in char_words:\n",
    "                    if char_counts.get(x) == None:\n",
    "                        char_counts.update({x : 1})\n",
    "                    else:\n",
    "                        char_counts.update({x : char_counts[x] + 1})\n",
    "                bow_non_vault.append(temp)\n",
    "                targets_non_vault.append(folder)\n",
    "            elif \"from the vault\" in file.lower():\n",
    "                name = file.replace(\".txt\", \"\")\n",
    "                text = get_clean_text(file, f\"lyrics/{folder}\")\n",
    "                temp_words = get_clean_words(text, \"\")\n",
    "                temp = [0] * len(words)\n",
    "                char_words = set(temp_words)\n",
    "                for x in temp_words:\n",
    "                    temp[words.index(x)] += 1\n",
    "                for x in char_words:\n",
    "                    if char_counts.get(x) == None:\n",
    "                        char_counts.update({x : 1})\n",
    "                    else:\n",
    "                        char_counts.update({x : char_counts[x] + 1})\n",
    "                bow_vault.append(temp)\n",
    "                targets_vault.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "8db9e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(bow_non_vault, targets_non_vault)\n",
    "probabilities = model.predict_proba(bow_vault)\n",
    "\n",
    "classes = model.classes_\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = (x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]])\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "897d40a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34615384615384615\n",
      "Accuracy Top 3: 0.5769230769230769\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(bow_vault)\n",
    "\n",
    "for i in range(len(bow_vault)):\n",
    "    if targets_vault[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow_vault)\n",
    "print(\"Accuracy:\", training_accuracy)\n",
    "\n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(bow_vault)):\n",
    "    if targets_vault[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow_vault)\n",
    "print(\"Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "e1d6fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6379310344827587\n",
      "\n",
      "Accuracy Top 3: 0.8850574712643678\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = 0\n",
    "correct = 0\n",
    "result = model.predict(bow_non_vault)\n",
    "\n",
    "for i in range(len(bow_non_vault)):\n",
    "    if targets_non_vault[i] == result[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow_non_vault)\n",
    "print(\"Accuracy:\", training_accuracy)\n",
    "\n",
    "probabilities = model.predict_proba(bow_non_vault)\n",
    "\n",
    "classes = model.classes_\n",
    "print()\n",
    "\n",
    "top = [0] * len(probabilities)\n",
    "ind = 0\n",
    "\n",
    "for x in probabilities:\n",
    "    idx = (-x).argsort()[:3]\n",
    "    top[ind] = list((x[idx[0]], classes[idx[0]], x[idx[1]], classes[idx[1]], x[idx[2]], classes[idx[2]]))\n",
    "    ind += 1\n",
    "    \n",
    "correct = 0\n",
    "    \n",
    "for i in range(len(bow_non_vault)):\n",
    "    if targets_non_vault[i] in top[i]:\n",
    "        correct += 1\n",
    "        \n",
    "training_accuracy = correct / len(bow_non_vault)\n",
    "print(\"Accuracy Top 3:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044b1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
